{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "FOLDS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and split to train and test set\n",
    "Use Breast Cancer dataset, where based on features, the existence of breast cancer is predicted.\n",
    "Check for class imbalance. Split into train and test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(as_frame=True, return_X_y=True)\n",
    "\n",
    "num_class_0, num_class_1 = (y == 0).sum(), (y == 1).sum()\n",
    "print('Number of data points belonging to class 0:', num_class_0)\n",
    "print('Number of data points belonging to class 1:', num_class_1)\n",
    "minority_class = num_class_0 if num_class_0 < num_class_1 else num_class_1\n",
    "print(f'''\n",
    "Data has {(minority_class / X.shape[0]):.2%} in the minority class.\n",
    "''')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=SEED)\n",
    "\n",
    "print(X.shape)\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare cross validation and models\n",
    "Since the dataset is small, we use only 5 folds.\n",
    "All models are applied with default hyperparameters for simplicity.\n",
    "Quick description of models used:\n",
    "- Ridge Regression: linear model with L2 loss to reduce overfitting\n",
    "- Support Vector Machine: finds hyperplane that maximizes margin between classes\n",
    "- Decision Tree: applies decision rules based on features to split data points into groups\n",
    "- Random Forest: aggregates results from multiple decision trees on randomly selected subsets of data\n",
    "- K-Nearest Neighbors: classifies data points based on *k* nearest neighbors\n",
    "- Gaussian Naive Bayes: Naive Bayes with assumption, that features within a class follow Gaussian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "scaler = StandardScaler()\n",
    "models = {\n",
    "  \"Ridge Regression\": RidgeClassifier(),\n",
    "  \"SVM\": SVC(),\n",
    "  \"Decision Tree\": DecisionTreeClassifier(),\n",
    "  \"Random Forest\": RandomForestClassifier(),\n",
    "  \"KNN\": KNeighborsClassifier(),\n",
    "  \"GaussianNB\": GaussianNB(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation function\n",
    "There are also `cross_validate` and `cross_val_score` in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(model, kfold, data, labels) -> list:\n",
    "  accuracies = []\n",
    "  for tr_index, val_index in kfold.split(data, labels):\n",
    "    X_tr, y_tr = data.iloc[tr_index], labels.iloc[tr_index]\n",
    "    X_val, y_val = data.iloc[val_index], labels.iloc[val_index]\n",
    "\n",
    "    # preprocess data after splitting to prevent data leakage\n",
    "    X_tr, X_val = scaler.fit_transform(X_tr), scaler.fit_transform(X_val)\n",
    "\n",
    "    model.fit(X_tr, y_tr)\n",
    "    accuracies.append( model.score(X_val, y_val))\n",
    "\n",
    "  return accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform cross validation and plot results\n",
    "Metric used is accuracy. Afterwards pick best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "for name, model in models.items():\n",
    "  accuracies = cross_validate(model, kf, X_train, y_train)\n",
    "  print(f\"Mean accuracy for {name}:\", np.mean(accuracies))\n",
    "  plt.plot(range(FOLDS), accuracies, label=name)\n",
    "plt.title(\"Accuracies of each fold across different classifiers\")\n",
    "plt.xlabel(\"Folds\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization\n",
    "Based on the performance of the previous cross validation, we assume SVM to be the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "  ('scaler', scaler),\n",
    "  ('model', models['SVM'])\n",
    "])\n",
    "parameters = {\n",
    "  'model__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "  'model__C': [.1, 1, 10],\n",
    "}\n",
    "clf = GridSearchCV(pipeline, parameters, cv=FOLDS, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit on whole training set and predict on whole test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(clf.best_params_)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
